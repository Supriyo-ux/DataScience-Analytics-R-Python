install.packages("E:/softwares/R/SDSFoundations_1.1.zip", repos = NULL, type = "win.binary")
library("SDSFoundations", lib.loc="~/R/win-library/3.4")
13+5
source('~/.active-rstudio-document')
a=13
a
remove(a)
y <- 1:10
y <- 1:10
x1 <- as.integer(2.00)
my.name <- as.integer(2.00)
my.number <- as.integer(readline(prompt = "Enter name:"))
for(i in c(1:nrow(my.number))){
my.number <- as.integer(readline(prompt = "Enter number:"))
}
install.packages("E:/softwares/R/SDSFoundations_1.1.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/user/Desktop/caret_6.0-82.zip", repos = NULL, type = "win.binary")
library(caret)
version
install.packages("tm")
install.packages("wordcloud")
install.packages("gmodels")
install.packages("e1071")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("e1071")
install.packages("randomForest")
install.packages("animation")
install.packages("neuralnet")
install.packages("boot")
install.packages("plyr")
install.packages("matrixStats")
library(ggplot2)
#data load and preparation
setwd("C:\\Users\\user\\Desktop\\data analytics\\neural network")
newyork<-read.csv("NYC_Free_Public_WiFi_03292017.csv",header = T)
setwd("C:\\Users\\user\\Desktop\\data analytics\\neural network")
newyork<-read.csv("NYC_Free_Public_WiFi_03292017.csv",header = T)
attach(newyork)
newyorkdf<-data.frame(newyork$LAT,newyork$LON)
wss <- (nrow(newyorkdf)-1)*sum(apply(newyorkdf,2,var))
for (i in 2:30) wss[i] <- sum(kmeans(newyorkdf,
centers=i)$withinss)
plot(1:30, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
set.seed(20)
fit <- kmeans(newyorkdf, 11) # 11 cluster solution
aggregate(newyorkdf,by=list(fit$cluster),FUN=mean)
newyorkdf <- data.frame(newyorkdf, fit$cluster)
newyorkdf
newyorkdf$fit.cluster <- as.factor(newyorkdf$fit.cluster)
ggplot(newyorkdf, aes(x=newyork.LON, y=newyork.LAT, color = newyorkdf$fit.cluster)) + geom_point()
library(neuralnet)
library(boot)
library(plyr)
library(matrixStats)
setwd("C:\\Users\\user\\Desktop\\data analytics\\neural network")
data = read.csv("cereals.csv", header=T)
View(data)
samplesize = 0.60 * nrow(data)
set.seed(80)
index = sample( seq_len ( nrow ( data ) ), size = samplesize )
# Create trainin
# Create trainin
datatrain = data[ index, ]
datatest = data[ -index, ]
max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
trainNN = scaled[index , ]
testNN = scaled[-index , ]
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3 , linear.output = T )
plot(NN)
predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
RMSE.NN = (sum((datatest$rating - predict_testNN)^2) / nrow(datatest)) ^ 0.5
set.seed(50)
k = 100
RMSE.NN = NULL
List = list( )
for(j in 10:65){
for (i in 1:k) {
index = sample(1:nrow(data),j )
trainNN = scaled[index,]
testNN = scaled[-index,]
datatest = data[-index,]
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3, linear.output= T)
predict_testNN = compute(NN,testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result*(max(data$rating)-min(data$rating)))+min(data$rating)
RMSE.NN [i]<- (sum((datatest$rating - predict_testNN)^2)/nrow(datatest))^0.5
}
List[[j]] = RMSE.NN
}
library(neuralnet)
library(boot)
library(plyr)
library(matrixStats)
setwd("C:\\Users\\user\\Desktop\\data analytics\\neural network")
data = read.csv("cereals.csv", header=T)
samplesize = 0.60 * nrow(data)
set.seed(80)
index = sample( seq_len ( nrow ( data ) ), size = samplesize )
datatrain = data[ index, ]
datatest = data[ -index, ]
max = apply(data , 2 , max)
min = apply(data, 2 , min)
scaled = as.data.frame(scale(data, center = min, scale = max - min))
trainNN = scaled[index , ]
testNN = scaled[-index , ]
set.seed(2)
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3 , linear.output = T )
plot(NN)
predict_testNN = compute(NN, testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result * (max(data$rating) - min(data$rating))) + min(data$rating)
plot(datatest$rating, predict_testNN, col='blue', pch=16, ylab = "predicted rating NN", xlab = "real rating")
abline(0,1)
RMSE.NN = (sum((datatest$rating - predict_testNN)^2) / nrow(datatest)) ^ 0.5
set.seed(50)
k = 100
RMSE.NN = NULL
List = list( )
for(j in 10:65){
for (i in 1:k) {
index = sample(1:nrow(data),j )
trainNN = scaled[index,]
testNN = scaled[-index,]
datatest = data[-index,]
NN = neuralnet(rating ~ calories + protein + fat + sodium + fiber, trainNN, hidden = 3, linear.output= T)
predict_testNN = compute(NN,testNN[,c(1:5)])
predict_testNN = (predict_testNN$net.result*(max(data$rating)-min(data$rating)))+min(data$rating)
RMSE.NN [i]<- (sum((datatest$rating - predict_testNN)^2)/nrow(datatest))^0.5
}
List[[j]] = RMSE.NN
}
Matrix.RMSE = do.call(cbind, List)
boxplot(Matrix.RMSE[,56], ylab = "RMSE", main = "RMSE BoxPlot (length of traning set = 65)")
med = colMedians(Matrix.RMSE)
X = seq(10,65)
plot (med~X, type = "l", xlab = "length of training set", ylab = "median RMSE", main = "Variation of RMSE with length of training set")
